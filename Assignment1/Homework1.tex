% --------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% --------------------------------------------------------------
 
\documentclass[12pt]{article}
 
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
 
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
 
\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{reflection}[2][Reflection]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{proposition}[2][Proposition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
 
\begin{document}
 
% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------
 
%\renewcommand{\qedsymbol}{\filledbox}
 
\title{Homework Assignment # 1: Probability Review}%replace X with the appropriate number
\author{Rushabh Ashok Dharia\\ %replace with your name
CSCI-B555 Machine Learning} %if necessary, replace with your course title
 
\maketitle

\begin{multline*}
    \text{\textbf{Note: }Homework was discussed with Varun Miranda and Bhushan Malgaonkar}
\end{multline*} 
 
\begin{theorem}[Ans]{1}
Container 1: 2000 Processors, 5\% defective = 100 defective processors\\
Container 2: 500 Processors, 15\% defective = 75  defective processors\\
Container 3: 600 Processors, 100  defective processors
 
\begin{proof}[a)]
P(C1) = P(C2) = P(C3) = 1/3 \\
P(D/C1) = 5/100, P(D/C2) = 15/100, P(D/C3) = 1/6 \\
\begin{align*}
P(\text{all 3 are defective}) 
& = \frac{100(99)(98)}{3(2000)(1999)(1998)} + \frac{75(74)(73)}{3(500)(499)(498)} + \frac{100(99)(98)}{3(600)(599)(598)} \\
& = 0.00263
\end{align*}
\end{proof}

\begin{proof}[b)]
\begin{align*}
P(\frac{C2}{3D}) & = \frac{P(C2).P(\frac{3D}{C2})}{P(3D)} \\
& = \frac{\frac{75(74)(73)}{3(500)(499)(498)}}{0.0263} \\
& = 0.413
\end{align*}
\end{proof}
\end{theorem}
\pagebreak
\begin{theorem}[Ans]{2}
A - P(H) = 0.75, P(T) = 0.25 \\
B - P(H) = 0.5, P(T) = 0.5 \\
C - P(H) = 0.25, P(T) = 0.75
\end{theorem}
 
\begin{proof}[a)] Different Permutations\\
\begin{align*}
HHH &=  3*0.75*0.5*0.25\\
HHT &= 2*0.75*0.5*0.75\\
HTH &= 2*0.75*0.5*0.25\\
HTT &= 1*0.75*0.5*0.75\\
THH &= 2*0.25*0.5*0.25\\
THT &= 1*0.25*0.5*0.75\\
TTH &= 1*0.25*0.5*0.25\\
TTT &= 0*0.25*0.5*0.75 \\
\\
E(X) &= \sum f_{i}x_{i} \\
& = 0.5*( 3*0.75*0.25 + 2*0.75^{2} + 2*0.75*0.25 +  0.75^{2} +  2*0.25^{2} + 0.25*0.75 + 0.25^{2}) \\
& = 0.5*( 3*0.75^{2} + (3+2+1)*0.75*0.25 + 3*0.25^{2} \\ 
& = \frac{3}{2}(0.75+0.25)^{2} \\
& = 1.5 
\end{align*}
\end{proof}

\begin{proof}[b)]
\begin{align*}
P(C/3H) &= \frac{P(C)*P(\frac{3H}{C})}{P(3H)}\\
&= \frac{\frac{1}{3}*0.25^{3}*0.75^{2}}{\frac{1}{3}*0.25^{3}*0.75^{2}+\frac{1}{3}*0.75^{3}*0.25^{2} + \frac{1}{3}*0.5^{5}} \\
&=0.1323
\end{align*}
\end{proof}
\pagebreak
\begin{theorem}[Ans]{3}
\begin{proof}[a)] Verification \\
\begin{align*}
0 &\leq \frac{\lambda^{x}e^{-\lambda}}{x!} \leq 1 \\ \text{And, }
\sum_{x=0}^{\infty} \frac{\lambda^{x}e^{-\lambda}}{x!}    
&= e^{-\lambda} \sum_{x=0}^{\infty}\frac{\lambda^{x}}{x!} & [Taylor Series &= 1+\lambda + \frac{\lambda^{2}}{2!}+....+\frac{\lambda^{3}}{3!} &= e^{\lambda}] \\
&= e^{-\lambda}*e^{\lambda}\\
&= 1 \\
\text{Therefore PMF is valid}
\end{align*}
\end{proof}

\begin{proof}[b)] 
\begin{align*}
E(\frac{1}{1+X}) &= \sum_{x=0}^{\infty} \frac{1}{1+x} P(X=x) \\   
&= \sum_{x=0}^{\infty} \frac{1}{1+x}  \frac{e^{-\lambda}\lambda^{x}}{x!}\\
&= e^{-\lambda}\sum_{x=0}^{\infty} \frac{1}{1+x}  \frac{\lambda^{x}}{x!}\\
&= e^{-\lambda}\sum_{x=0}^{\infty} \frac{\lambda^{x}}{(x+1)!}\\
&= \frac{e^{-\lambda}}{\lambda}\sum_{x=0}^{\infty} \frac{\lambda^{x+1}}{(x+1)!} [\text{put } y=x+1. \text{Therefore when } x=0, y=1 \text{ and when } x=\infty y=\infty]\\
&= \frac{e^{-\lambda}}{\lambda}[\sum_{y=1}^{\infty}\frac{\lambda^{y}}{y!}] \\
&\text{For y=0 } \frac{\lambda^{0}}{0!}=1 \\
&\text{Therefore, adding + 1 and -1 to the above equation, we get }\\
&= \frac{e^{-\lambda}}{\lambda}[\sum_{y=0}^{\infty}\frac{\lambda^{y}}{y!}-1]\\
&=\frac{e^{-\lambda}}{\lambda}(e^{\lambda}-1) \text{ [Using Taylor series]}\\
&= \frac{1-e^{-\lambda}}{\lambda}
\end{align*}
\end{proof}
\end{theorem}
\pagebreak
\begin{theorem}[Ans]{4}
\begin{proof}[a)]
\begin{align*}
\text{Arc Length }S = r\theta = X\\ 
\text{Area = }\frac{r^{2}\theta}{2} = Y\\
2\pi r = 1\\
r = \frac{1}{2\pi}
\frac{X}{Y} = \frac{r\theta}{\frac{r^{2}\theta}{2}}\\
\frac{X}{Y} = \frac{2}{r} = 2*2\pi\\
Y = \frac{X}{4\pi}\\
\end{align*}
\end{proof}

\begin{proof}[b)]
\begin{align*}
F_{Y}(y) &= P(Y\leq y)\\
&= P(\frac{X}{4\pi})\\
&= P(X\leq 4\pi y)\\
\text{Therefore, }
\end{align*}
\[  F_{Y}(y) =  \left\{
\begin{array}{ll}
      0 & y\leq 0 \\
      4\pi y & 0\leq y\leq \frac{1}{4\pi} \\
\end{array} 
\right. \]
\end{proof}

\begin{proof}[c)]
\begin{align*}
f_{Y}(y) &= \frac{d}{dx}F_{Y}(y) 
\end{align*}
\[   f_{Y}(y) =\left\{ 
\begin{array}{ll}
4\pi & 0\leq y\leq \frac{1}{4\pi} \\
      0 & \text{Otherwise}\\
\end{array} 
\right. \]
\end{proof}
\end{theorem}

\begin{proof}[d)]
\begin{align*}
E[Y] &= \int_{-\infty}^{\infty} g(y).f(y) dy \\
&= \int_{0}^{\frac{1}{4\pi}}y.4\pi dy\\
&=4\pi \int_{0}^{\frac{1}{4\pi}} y dy\\
&=\frac{1}{8\pi}
\end{align*} 
\end{proof}
\pagebreak
\begin{theorem}[Ans]{5}
\begin{proof}[a)]
\begin{align*}
    E[N] & = \sum_{n\in N}n.p_{N}(n) \\
    &= 1.\frac{1}{10} + 2.\frac{2}{10} + 3.\frac{3}{10} + 4.\frac{4}{10}\\
    &= 3\\
    V[N] &= E[N^{2}] - E[N]^{2}\\
    E[N^2]&=\sum_{n\in N} n^{2}p_{N}(n)\\
    &=1.\frac{1}{10} + 2.\frac{2^{3}}{10} + 3.\frac{3^{3}}{10} + 4.\frac{4^{3}}{10}\\
    &=10\\
    \text{Therefore, }V[N]&= 10-9 \\&= 1
\end{align*}
\end{proof}

\begin{proof}[b)]
\begin{align*}
p_{N/X}(n/x) &= \frac{p_{X/N}(x/n).p_{N}(n)}{p_{X}(x)}\\
p(x=0) &= \sum_{n\in N}p(x=0,n)\\
&= \sum_{n\in N}p(x=0/n).p(n)\\
&= p(x=0/n=1).p(n=1)+p(x=0/n=2).p(n=2)\\&+p(x=0/n=3).p(n=3)+p(x=0/n=4).p(n=4)\\
&=0.\frac{1}{10}+\frac{1}{4}.\frac{2}{10}+\frac{1}{3}.\frac{3}{10}+\frac{3}{8}.\frac{4}{10}\\
&=\frac{3}{10}\\
\text{Since }X\in \{0,1\}\\
p(x=1)&=1-p(x=0)\\
&= \frac{7}{10}\\
\text{For }X=0,\\
p(n=1/x=0)&=\frac{p(x=0/n=1).p(n=1)}{p(x=0)}\\
&=\frac{\frac{0x1}{10}}{\frac{3}{10}}\\
&=0\\
p(n=2/x=0)&=\frac{p(x=0/n=2).p(n=2)}{p(x=0)}\\
&=\frac{\frac{1x2}{4x10}}{\frac{3}{10}}\\
&=\frac{1}{6}\\
p(n=3/x=0)&=\frac{p(x=0/n=3).p(n=3)}{p(x=0)}\\
&=\frac{\frac{1x3}{3x10}}{\frac{3}{10}}\\
&=\frac{1}{3}\\
p(n=4/x=0)&=\frac{p(x=0/n=4).p(n=4)}{p(x=0)}\\
&=\frac{\frac{3x4}{8x10}}{\frac{3}{10}}\\
&=\frac{1}{2}\\
\end{align*}
\begin{align*}
\text{For }X=1,\\
p(n=1/x=1)&=\frac{p(x=1/n=1).p(n=1)}{p(x=1)}\\
&=\frac{1x\frac{1}{10}}{\frac{7}{10}}\\
&=\frac{1}{7}\\
p(n=2/x=1)&=\frac{p(x=1/n=2).p(n=2)}{p(x=1)}\\
&=\frac{\frac{3x2}{4x10}}{\frac{7}{10}}\\
&=\frac{3}{14}\\
p(n=3/x=1)&=\frac{p(x=1/n=3).p(n=3)}{p(x=1)}\\
&=\frac{\frac{2x3}{3x10}}{\frac{7}{10}}\\
&=\frac{2}{7}\\
p(n=4/x=1)&=\frac{p(x=1/n=4).p(n=4)}{p(x=1)}\\
&=\frac{\frac{5x4}{8x10}}{\frac{7}{10}}\\
&=\frac{5}{14}\\    
\end{align*}
\end{proof}
\begin{center}
 \begin{tabular}{|c c c c c|} 
 \hline
 n/x & n=1 & n=2 & n=3 & n=4\\ [0.5ex] 
 \hline\hline
 x=0 & 0 & 1/6 & 1/3 & 1/2\\ 
 \hline
 x=1 & 1/7 & 3/14 & 2/7 & 5/14 \\[1ex] 
 \hline
\end{tabular}
\end{center}
\begin{proof}[c)]
\begin{align*}
    E[N|X=1] &= \sum_{n\in N} n.p(N=n|X=1)\\
    &= 1.p(N=1|X=1)+2.p(N=2|X=1)+3.p(N=3|X=1)+4.p(N=4|X=1)\\
    &=1.\frac{1}{7}+2.\frac{3}{14}+3.\frac{2}{7}+4..\frac{5}{14}\\
    &=\frac{20}{7}
\end{align*}
\end{proof}
\end{theorem}
\pagebreak
\begin{theorem}[Ans]{6}
\begin{proof}[a)]
\begin{align*}
    f_{Y|X}(Y|X)&=\frac{f_{XY}(x,y)}{f_{X}(x)}\\
    \text{Now, }f_{X}(x) &= \int_{0}^{4-2x}\frac{3}{16}(4-2x-y)dy\\
    &= \frac{3}{16}[(4-2x)\int_{0}^{4-2x}1dy+\int_{0}^{4-2x}ydy]\\
    &= \frac{3}{16}[(4-2x)^{2}-\frac{(4-2x)^{2}}{2}]\\
    &= \frac{3*(4-2x)^{2}}{16*2}\\
    &= \frac{3*4*(2-x)^{2}}{32}\\
    &= \frac{3*(2-x)^{2}}{8}\\
    \text{Therefore, }f_{Y|X}(Y|X) &= \frac{\frac{3}{16}(4-2x-y)}{\frac{3}{8}(2-x)^{2}}\\
    &=\frac{1}{2}.\frac{4-2x-y}{(2-x)^{2}}\\
\end{align*}
\end{proof}

\begin{proof}[b)]
\begin{align*}
    P(Y\geq2|X=1/2)&=\int_{2}^{3}\frac{3-y}{2(2-\frac{1}{2})^{2}}dy\\
    &=\int_{2}^{3}\frac{3-y}{\frac{2*9}{4}}\\
    &=\frac{2}{9}\int_{2}^{3}(3-y)dy\\
    &=\frac{2}{9}(3\int_{2}^{3}1dy-\int_{2}^{3}ydy)\\
    &= \frac{2}{9}(3(1)-\frac{9-4}{2})\\
    &=\frac{1}{9}
\end{align*}
\end{proof}

\begin{proof}[c)]
\begin{align*}
    E(Y|X) &= \int_{0}^{4-2x}Y.F(Y|X)dy\\
    &=\int_{0}^{4-2x}y.\frac{1}{2}.\frac{4-2x-y}{(2-x)^{2}}dy\\
    &=\frac{1}{2.(2-x)^{2}}\int_{0}^{4-2x}(4-2x).y-y^{2}dy\\
    &=\frac{1}{2.(2-x)^{2}}((4-2x)\int_{0}^{4-2x}ydy-\int_{0}^{4-2x}y^{2}dy)\\
    &= \frac{1}{2.(2-x)^{2}}(\frac{(4-2x).(4-2x)^2}{2}-\frac{(4-2x)^{3}}{3})\\
    &= \frac{1}{2.(2-x)^{2}}\frac{(4-2x)^{3}}{12(2-x)^{2}}\\
    &= \frac{8*(2-x)^{3}}{12*(2-x)^{2}}\\
    &= \frac{2}{3}(2-x)
\end{align*}
\end{proof}
\end{theorem}
\begin{theorem}[Ans]{7}
\end{theorem}
   a) 68\% values lie within 1 standard deviation. According to the Central limit theorem, when we increase number of samples we get answer nearer to the actual mean. Therefore, as we increase the number of samples in simulate.py we get the answer nearer to 0.\\
    Now, 99.7 values lie within 3 standard deviation. So when we set the standard deviation to 10 we get a lot more varied samples in comparison to standard deviation = 1. Therefore, we get the answer which is not as close to the actual mean in comparison to s.d=1 \\
b)For the co-variance $\begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1 
\end{bmatrix}$ the samples of the normal distribution have freedom in all 3 Dimensions so they scatter around the 3D space
\\When we change the co-variance to 
$\begin{bmatrix}
    1 & 0 & 1 \\
    0 & 1 & 0 \\
    1 & 0 & 1 
\end{bmatrix}$
, all points lie in the x-z=0 plane since x = 1 and z =1 and y =0
% --------------------------------------------------------------
%     You don't have to mess with anything below this line.
% --------------------------------------------------------------
 
\end{document}